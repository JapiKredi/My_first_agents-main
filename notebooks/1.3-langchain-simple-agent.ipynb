{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], optional_variables=['chat_history'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x1069089a0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]], 'agent_scratchpad': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x1069089a0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={'chat_history': []}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'openai-tools-agent', 'lc_hub_commit_hash': 'c18672812789a3b9697656dd539edf0120285dcae36396d0b548ae42a4ed66f5'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), MessagesPlaceholder(variable_name='agent_scratchpad')])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import hub\n",
    "\n",
    "prompt_agent = hub.pull('hwchase17/openai-tools-agent')\n",
    "\n",
    "prompt_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv('/Users/jasper/Downloads/My_first_agents-main/notebooks/.env')\n",
    "\n",
    "# Verify that the API key is loaded\n",
    "api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "#load_dotenv('/Users/jasper/Downloads/My_first_agents-main/notebooks/.env')\n",
    "\n",
    "# Verify that the API key is loaded\n",
    "tavily_api_key = os.getenv('TAVILY_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 8, 'total_tokens': 17, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0aa8d3e20b', 'finish_reason': 'stop', 'logprobs': None}, id='run-07e7eb52-e53d-445a-93f7-6da6798149c6-0', usage_metadata={'input_tokens': 8, 'output_tokens': 9, 'total_tokens': 17, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-4o-mini', temperature=0, openai_api_key=api_key)\n",
    "\n",
    "llm.invoke(\"HI\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agent = LLM + Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0-langchain-basics.ipynb\\n1.1-langchain-simple-chains.ipynb\\n1.2-langchain-runnables-and-lcel.ipynb\\n1.3-langchain-simple-agent.ipynb\\n2.0-autogen-building-agents.ipynb\\n2.1-autogen-building-research-assistant.ipynb\\n3.0-langgraph-building-stateful-applications.ipynb\\n3.1-langgraph-buid-research-assistant.ipynb\\n4.0-rag-agent-langgraph.ipynb\\n4.1-autogen-multi-agent-workflows.ipynb\\nAutogen Demo Notebook.ipynb\\nTool Use.ipynb\\nagentic-rag-langgraph.ipynb\\n\\x1b[1m\\x1b[36massets-resources\\x1b[m\\x1b[m\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "@tool\n",
    "def list_files():\n",
    "    \"\"\"List files in current directory\"\"\"\n",
    "    return subprocess.run([\"ls\"], stdout=subprocess.PIPE).stdout.decode(\"utf-8\")\n",
    "\n",
    "\n",
    "list_files.invoke({\"input\": \"\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x1088f4190>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x10893a2d0>, root_client=<openai.OpenAI object at 0x1088cfc10>, root_async_client=<openai.AsyncOpenAI object at 0x10891c890>, model_name='gpt-4o-mini', temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********')), kwargs={'tools': [{'type': 'function', 'function': {'name': 'list_files', 'description': 'List files in current directory', 'parameters': {'properties': {}, 'type': 'object'}}}]}, config={}, config_factories=[])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_with_tool = llm.bind_tools([list_files])\n",
    "\n",
    "llm_with_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_rvyEIE5amrHVqjTkWnEsxad0', 'function': {'arguments': '{}', 'name': 'list_files'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 42, 'total_tokens': 52, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_d02d531b47', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-4ab78625-a55a-4539-a331-b1875e3b1dfd-0', tool_calls=[{'name': 'list_files', 'args': {}, 'id': 'call_rvyEIE5amrHVqjTkWnEsxad0', 'type': 'tool_call'}], usage_metadata={'input_tokens': 42, 'output_tokens': 10, 'total_tokens': 52, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_with_tool.invoke(\"List files in current directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0-langchain-basics.ipynb\n",
      "1.1-langchain-simple-chains.ipynb\n",
      "1.2-langchain-runnables-and-lcel.ipynb\n",
      "1.3-langchain-simple-agent.ipynb\n",
      "2.0-autogen-building-agents.ipynb\n",
      "2.1-autogen-building-research-assistant.ipynb\n",
      "3.0-langgraph-building-stateful-applications.ipynb\n",
      "3.1-langgraph-buid-research-assistant.ipynb\n",
      "4.0-rag-agent-langgraph.ipynb\n",
      "4.1-autogen-multi-agent-workflows.ipynb\n",
      "Autogen Demo Notebook.ipynb\n",
      "Tool Use.ipynb\n",
      "agentic-rag-langgraph.ipynb\n",
      "\u001b[1m\u001b[36massets-resources\u001b[m\u001b[m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dictionary_with_tool_names = {\n",
    "    \"list_files\": list_files,\n",
    "}\n",
    "\n",
    "output = llm_with_tool.invoke(\"List files in current directory\")\n",
    "\n",
    "if output.tool_calls:\n",
    "    for tool_call in output.tool_calls:\n",
    "        tool_name = tool_call[\"name\"]\n",
    "        tool_args = tool_call['args']\n",
    "        tool_func = dictionary_with_tool_names[tool_name]\n",
    "        print(tool_func.invoke(tool_args))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agent = LLM + tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/vidhya-agents/lib/python3.11/site-packages/langchain/chains/api/base.py:56: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  from langchain_community.utilities.requests import TextRequestsWrapper\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import create_tool_calling_agent, AgentExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [list_files]\n",
    "\n",
    "agent = create_tool_calling_agent(llm, tools, prompt_agent)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `list_files` with `{}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m1.0-langchain-basics.ipynb\n",
      "1.1-langchain-simple-chains.ipynb\n",
      "1.2-langchain-runnables-and-lcel.ipynb\n",
      "1.3-langchain-simple-agent.ipynb\n",
      "2.0-autogen-building-agents.ipynb\n",
      "2.1-autogen-building-research-assistant.ipynb\n",
      "3.0-langgraph-building-stateful-applications.ipynb\n",
      "3.1-langgraph-buid-research-assistant.ipynb\n",
      "4.0-rag-agent-langgraph.ipynb\n",
      "4.1-autogen-multi-agent-workflows.ipynb\n",
      "Autogen Demo Notebook.ipynb\n",
      "Tool Use.ipynb\n",
      "agentic-rag-langgraph.ipynb\n",
      "\u001b[1m\u001b[36massets-resources\u001b[m\u001b[m\n",
      "\u001b[0m\u001b[32;1m\u001b[1;3mHere are the files in the current directory:\n",
      "\n",
      "1. 1.0-langchain-basics.ipynb\n",
      "2. 1.1-langchain-simple-chains.ipynb\n",
      "3. 1.2-langchain-runnables-and-lcel.ipynb\n",
      "4. 1.3-langchain-simple-agent.ipynb\n",
      "5. 2.0-autogen-building-agents.ipynb\n",
      "6. 2.1-autogen-building-research-assistant.ipynb\n",
      "7. 3.0-langgraph-building-stateful-applications.ipynb\n",
      "8. 3.1-langgraph-buid-research-assistant.ipynb\n",
      "9. 4.0-rag-agent-langgraph.ipynb\n",
      "10. 4.1-autogen-multi-agent-workflows.ipynb\n",
      "11. Autogen Demo Notebook.ipynb\n",
      "12. Tool Use.ipynb\n",
      "13. agentic-rag-langgraph.ipynb\n",
      "14. assets-resources (directory)\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'List files in current directory',\n",
       " 'output': 'Here are the files in the current directory:\\n\\n1. 1.0-langchain-basics.ipynb\\n2. 1.1-langchain-simple-chains.ipynb\\n3. 1.2-langchain-runnables-and-lcel.ipynb\\n4. 1.3-langchain-simple-agent.ipynb\\n5. 2.0-autogen-building-agents.ipynb\\n6. 2.1-autogen-building-research-assistant.ipynb\\n7. 3.0-langgraph-building-stateful-applications.ipynb\\n8. 3.1-langgraph-buid-research-assistant.ipynb\\n9. 4.0-rag-agent-langgraph.ipynb\\n10. 4.1-autogen-multi-agent-workflows.ipynb\\n11. Autogen Demo Notebook.ipynb\\n12. Tool Use.ipynb\\n13. agentic-rag-langgraph.ipynb\\n14. assets-resources (directory)'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({'input': \"List files in current directory\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `list_files` with `{}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m1.0-langchain-basics.ipynb\n",
      "1.1-langchain-simple-chains.ipynb\n",
      "1.2-langchain-runnables-and-lcel.ipynb\n",
      "1.3-langchain-simple-agent.ipynb\n",
      "2.0-autogen-building-agents.ipynb\n",
      "2.1-autogen-building-research-assistant.ipynb\n",
      "3.0-langgraph-building-stateful-applications.ipynb\n",
      "3.1-langgraph-buid-research-assistant.ipynb\n",
      "4.0-rag-agent-langgraph.ipynb\n",
      "4.1-autogen-multi-agent-workflows.ipynb\n",
      "Autogen Demo Notebook.ipynb\n",
      "Tool Use.ipynb\n",
      "agentic-rag-langgraph.ipynb\n",
      "\u001b[1m\u001b[36massets-resources\u001b[m\u001b[m\n",
      "\u001b[0m\u001b[32;1m\u001b[1;3mThe current directory contains the following files:\n",
      "\n",
      "1. `1.0-langchain-basics.ipynb`\n",
      "2. `1.1-langchain-simple-chains.ipynb`\n",
      "3. `1.2-langchain-runnables-and-lcel.ipynb`\n",
      "4. `1.3-langchain-simple-agent.ipynb`\n",
      "5. `2.0-autogen-building-agents.ipynb`\n",
      "6. `2.1-autogen-building-research-assistant.ipynb`\n",
      "7. `3.0-langgraph-building-stateful-applications.ipynb`\n",
      "8. `3.1-langgraph-buid-research-assistant.ipynb`\n",
      "9. `4.0-rag-agent-langgraph.ipynb`\n",
      "10. `4.1-autogen-multi-agent-workflows.ipynb`\n",
      "11. `Autogen Demo Notebook.ipynb`\n",
      "12. `Tool Use.ipynb`\n",
      "13. `agentic-rag-langgraph.ipynb`\n",
      "14. `assets-resources` (directory)\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What kind of files are in the current directory?',\n",
       " 'output': 'The current directory contains the following files:\\n\\n1. `1.0-langchain-basics.ipynb`\\n2. `1.1-langchain-simple-chains.ipynb`\\n3. `1.2-langchain-runnables-and-lcel.ipynb`\\n4. `1.3-langchain-simple-agent.ipynb`\\n5. `2.0-autogen-building-agents.ipynb`\\n6. `2.1-autogen-building-research-assistant.ipynb`\\n7. `3.0-langgraph-building-stateful-applications.ipynb`\\n8. `3.1-langgraph-buid-research-assistant.ipynb`\\n9. `4.0-rag-agent-langgraph.ipynb`\\n10. `4.1-autogen-multi-agent-workflows.ipynb`\\n11. `Autogen Demo Notebook.ipynb`\\n12. `Tool Use.ipynb`\\n13. `agentic-rag-langgraph.ipynb`\\n14. `assets-resources` (directory)'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({'input': \"What kind of files are in the current directory?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"TAVILY_API_KEY\"] = 'YOUR TAVILY API KEY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import TavilySearchResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AttributeError(\"\\'FieldInfo\\' object has no attribute \\'raw_results\\'\")'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_tool = TavilySearchResults(\n",
    "    max_results = 5,\n",
    "    search_depth=\"advanced\",\n",
    "    include_answer=True,\n",
    ")\n",
    "\n",
    "search_tool.invoke('What is the capital of France?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def create_file(file_path: str, content: str):\n",
    "    \"\"\"Create a file with the given content\"\"\"\n",
    "    with open(file_path, 'w') as f:\n",
    "        f.write(content)\n",
    "    return f\"File created at {file_path} with content: {content}\"\n",
    "\n",
    "tools = [create_file, search_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentExecutor(verbose=True, agent=RunnableMultiActionAgent(runnable=RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(lambda x: message_formatter(x['intermediate_steps']))\n",
       "})\n",
       "| ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], optional_variables=['chat_history'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x1069089a0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]], 'agent_scratchpad': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x1069089a0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={'chat_history': []}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'openai-tools-agent', 'lc_hub_commit_hash': 'c18672812789a3b9697656dd539edf0120285dcae36396d0b548ae42a4ed66f5'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), MessagesPlaceholder(variable_name='agent_scratchpad')])\n",
       "| RunnableBinding(bound=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x1088f4190>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x10893a2d0>, root_client=<openai.OpenAI object at 0x1088cfc10>, root_async_client=<openai.AsyncOpenAI object at 0x10891c890>, model_name='gpt-4o-mini', temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********')), kwargs={'tools': [{'type': 'function', 'function': {'name': 'create_file', 'description': 'Create a file with the given content', 'parameters': {'properties': {'file_path': {'type': 'string'}, 'content': {'type': 'string'}}, 'required': ['file_path', 'content'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'tavily_search_results_json', 'description': 'A search engine optimized for comprehensive, accurate, and trusted results. Useful for when you need to answer questions about current events. Input should be a search query.', 'parameters': {'type': 'object', 'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query']}}}]}, config={}, config_factories=[])\n",
       "| ToolsAgentOutputParser(), input_keys_arg=[], return_keys_arg=[], stream_runnable=True), tools=[StructuredTool(name='create_file', description='Create a file with the given content', args_schema=<class 'langchain_core.utils.pydantic.create_file'>, func=<function create_file at 0x10aaee3e0>), TavilySearchResults(include_answer=True, api_wrapper=FieldInfo(default=PydanticUndefined, default_factory=<class 'langchain_community.utilities.tavily_search.TavilySearchAPIWrapper'>, extra={}))])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_research_agent = create_tool_calling_agent(llm, tools, prompt_agent)\n",
    "\n",
    "simple_research_agent_executor = AgentExecutor(agent=simple_research_agent, tools=tools, verbose=True)\n",
    "\n",
    "simple_research_agent_executor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `tavily_search_results_json` with `{'query': 'Paris Olympics 2024 highlights'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mAttributeError(\"'FieldInfo' object has no attribute 'raw_results'\")\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `tavily_search_results_json` with `{'query': 'Paris Olympics 2024 highlights summary'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mAttributeError(\"'FieldInfo' object has no attribute 'raw_results'\")\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `tavily_search_results_json` with `{'query': 'Paris 2024 Olympics main highlights'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mAttributeError(\"'FieldInfo' object has no attribute 'raw_results'\")\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `tavily_search_results_json` with `{'query': 'Paris Olympics 2024 news highlights'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mAttributeError(\"'FieldInfo' object has no attribute 'raw_results'\")\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `tavily_search_results_json` with `{'query': 'Paris 2024 Olympics key highlights'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mAttributeError(\"'FieldInfo' object has no attribute 'raw_results'\")\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `tavily_search_results_json` with `{'query': 'Paris 2024 Olympics overview'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mAttributeError(\"'FieldInfo' object has no attribute 'raw_results'\")\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `tavily_search_results_json` with `{'query': 'Paris 2024 Olympics summary'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mAttributeError(\"'FieldInfo' object has no attribute 'raw_results'\")\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `tavily_search_results_json` with `{'query': 'Paris 2024 Olympics updates'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mAttributeError(\"'FieldInfo' object has no attribute 'raw_results'\")\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `tavily_search_results_json` with `{'query': 'Paris 2024 Olympics news'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mAttributeError(\"'FieldInfo' object has no attribute 'raw_results'\")\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `tavily_search_results_json` with `{'query': 'Paris 2024 Olympics events and highlights'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mAttributeError(\"'FieldInfo' object has no attribute 'raw_results'\")\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `tavily_search_results_json` with `{'query': 'Paris 2024 Olympics schedule and highlights'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mAttributeError(\"'FieldInfo' object has no attribute 'raw_results'\")\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `tavily_search_results_json` with `{'query': 'Paris 2024 Olympics key events and highlights'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mAttributeError(\"'FieldInfo' object has no attribute 'raw_results'\")\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `tavily_search_results_json` with `{'query': 'Paris 2024 Olympics major highlights'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mAttributeError(\"'FieldInfo' object has no attribute 'raw_results'\")\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `tavily_search_results_json` with `{'query': 'Paris 2024 Olympics preview'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mAttributeError(\"'FieldInfo' object has no attribute 'raw_results'\")\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `tavily_search_results_json` with `{'query': 'Paris 2024 Olympics features'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mAttributeError(\"'FieldInfo' object has no attribute 'raw_results'\")\u001b[0m\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Agent stopped due to max iterations."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "output_report = simple_research_agent_executor.invoke({'input': 'Write a summarized report about the main highlights of the Paris Olympics 2024 and save it locally as report-olympics-2024.md'})\n",
    "\n",
    "Markdown(output_report['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'report-olympics-2024.md'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreport-olympics-2024.md\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      2\u001b[0m     content_report \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m      4\u001b[0m Markdown(content_report)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/vidhya-agents/lib/python3.11/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'report-olympics-2024.md'"
     ]
    }
   ],
   "source": [
    "with open('report-olympics-2024.md', 'r') as f:\n",
    "    content_report = f.read()\n",
    "    \n",
    "Markdown(content_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vidhya-agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
